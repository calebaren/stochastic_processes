---
title: "Chapter 8: Brownian Motion"
output: pdf_document
date: '2022-05-30'
---
\newcommand{\Var}{\textrm{Var}}
\newcommand{\Cov}{\textrm{Cov}}
\newcommand{\soln}{\textbf{Solution:}}
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r brownian, eval=FALSE, include=FALSE}
wiener_process <- function(t) {
  # time t
  # steps n
  n <- 1000
  bm <- c(0, cumsum(rnorm(n, 0, sqrt(t/n))))
  steps <- seq(0,t,length = n+1)
  bm
}
```

# Examples
## Example 8.1

For $0 < s < t$, find the distribution of $B_s + B_t$.
$$
B_s + B_t = B_s + B_s + B_t - B_s = 2B_s + (B_t - B_s)
$$

By independent increments, $B_s$ and $B_t - B_s$ are independent random variables.
$$
\begin{gathered}
E(B_s + B_t) = E(B_s) + E(B_t) = 0 \\
\Var(B_s + B_t) = \Var(2B_s + (B_t - B_s)) = 4Var(B_s) + \Var(B_t-B_s) \\
= 4s + t-s \\
= 3s+t
\end{gathered}
$$

Therefore, $B_s + B_t \sim \mathcal{N}(0, 3s+t)$.

## Example 8.2

If a standard Brownian motion particle is at position 1 at time 2, find the probability that the position is at most 3 at time 5.

By stationary increments, $B_5 - B_2 \sim B_3$.
$$
P(B_5 \le 3 \mid B_2 = 1) = P(B_5 - B_2 \le 3 - B_2 \mid B_2 = 1) \\
= P(B_5 - B_2 \le 2) \\
= P(B_3 \le 2) = 0.876
$$

## Example 8.3

Find the covariance of $B_s$ and $B_t$.

$$
\Cov(B_s, B_t) = E(B_sB_t) - E(B_s)E(B_t) = E(B_sB_t)
$$

Assuming that $s < t$:

$$
\begin{gathered}
B_t = B_s + (B_t - B_s) \\
E(B_sB_t) = E(B_s(B_s + (B_t - B_s))) \\
= E(B_s^2 + B_s(B_t - B_s)) \\
= E(B_s^2) + E(B_s(B_t-B_s)) \\
=\Var(B_s) + E(B_s)E(B_t-B_s) \\
=s + 0 = s
\end{gathered}
$$

By symmetry, if $t < s$, then $\Cov(B_sB_t) = t$. In general, $\Cov(B_sB_t) = \min(s, t)$.

## Example 8.4

For a simple symmetric random walk, consider the maximum of the walk in the first $n$ steps. Let $g(f) = \max_{0 \le t \le 1} f(t)$.

By the invariance principle, $g(S_{nt} / \sqrt{n}) \approx g(B_t)$ for large $n$. 

$$
\lim_{n\rightarrow\infty} g\left(\frac{S_{nt}} {\ \sqrt{n}}\right) =  \lim_{n \rightarrow \infty} \max_{0 \le t \le 1} \left(\frac{S_{nt}}{\sqrt{n}}\right) = \lim_{n\rightarrow\infty} \max_{0 \le k \le n}\left(\frac{S_k}{\sqrt{n}}\right)
$$

This converges to $g(B_t) = \max_{0\le t \le 1}(B_t)$ in the limit. 

$$
\begin{gathered}
\max_{0 \le k \le n} S_k / \sqrt{n} = \max_{0\le t \le 1}(B_t) \\
\max_{0\le k\le n} S_k = \sqrt{n} \max_{0 \le t \le 1} (B_t)
\end{gathered}
$$

$\max_{0\le t \le 1}(B_t)$ has density $f(x) = \sqrt{2/\pi}\exp({-x^2/2})$ for $x > 0$. If $n = 10,000$ steps, the probability that a value greater than 200 is reached is:

$$
P\left(\max_{0 \le k \le n}S_k > 200\right) \\
= P\left(\max_{0 \le k \le n}\frac{S_k}{100} > 2\right) \\
= P\left(\max_{0 \le k \le n}\frac{S_k}{\sqrt{n}} > 2\right) \\
= P(M > 2) = 0.0455
$$

```{r}
# simulating a random walk with 10000 steps
n <- 10000
nsim <- 10000
sim <- replicate(nsim,
                 max(cumsum(sample(size=n, c(-1,1), replace = T))))

mean(sim)
sd(sim)

sim <- replicate(nsim,
                 ifelse(max(cumsum(sample(c(-1, 1), n, replace = T))) > 200, 1, 0))

mean(sim)
```

## Example 8.5

For $a>0$, let $X_t = B_{at}/\sqrt{a}$ for $t \ge 0$. Show that $X_t$ is a standard Brownian motion.

The linear combination of $X_k$ for $0 \le t_1 < \dots < t_k$ is 

$$
\sum_{i=1}^k a_iX_{t_i} = \sum_{i=1}^k \frac{a_i}{\sqrt{a}}B_{at}
$$

This has a univariate Normal distribution since $B_{at}$ is a standard Brownian motion process and is thus a Gaussian process. $X_0 = 0$ since $B_0 = 0$. The mean function is:
$$
E(X_t) = E(B_{at} / \sqrt{a}) = 0
$$

The covariance is:
$$
\begin{gathered}
\Cov(X_s, X_t) = \Cov(B_{as} / \sqrt{a}, B_{at} / \sqrt{a}) \\
= \frac{1}{a}\Cov(B_{as}, B_{at}) \\
= \frac1a \min(as, at) = min(s, t)
\end{gathered}
$$

Finally, because $B_t$ is path continuous, $X_t$ is path continuous for all $a>0$.

## Example 8.6

Let $(X_t)_{t \ge 0}$ be a Brownian motion process started at $x=3$. Find $P(X_2 > 0)$.

Write $X_t = B_t + 3$. Then,

$$
P(X_2 > 0) = P(B_2 + 3 > 0) = P(B_2 > -3) = 0.983
$$

## Example 8.7

A particle moves according to Brownian motion started at $x=1$. After $t=3$ hours, the particle is at level 1.5. Find the probability that the particle reaches level 2 sometime in the next hour. 

The translated process is a Brownian motion process started at $x=1.5$. The event that the translated process hits level 2 within the next hour is equal to the event that a standard Brownian motion process hits $x = 2-1.5 = 0.5$ within the next hour.

$$
P(T_{0.5} < 1) = \int_0^1 f_{T_{0.5}}(t) \, dt
= \int_0^1 \frac{0.5}{\sqrt{2\pi t^3}} e^{-0.5^2 / 2t} \, dt = 0.617
$$

## Example 8.8

A laboratory instrument takes annual temperature measurements. Measurement errors are assumed to be independent and Normally distributed. As precision decreases over time, errors are modeled as standard Brownian motion. for how many years can the lab be guaranteed that there is at least 90\% probability that errors are less than 4 degrees?

Let $B_t$ be the error at time $t$. Find $t$ such that $P(M_t < 4) \ge 90\%$.

$$
0.9 \le P(M_t < 4) = 1 -P(M_t \ge 4) = 1-2P(B_t \ge 4) = 2P(B_t < 4) - 1
$$

This yields

$$
0.95 \le P(B_t < 4) = P\left(Z \le \frac{4}{\sqrt t}\right)
$$

The 95th percentile of the standard Normal distribution is 1.645:

$$
\begin{gathered}
1.645 = \frac{4}{\sqrt{t}} \\
t = \left(\frac{4}{1.645}\right)^2 = 5.91
\end{gathered}
$$

## Last Even Time

Flip a coin $n=10,000$ times. If heads, A pays B \$1, otherwise if tails, B pays A. Let $\tilde{L}_n$ be the last time in $n$ times that the players are tied (aka the last zero in a simple symmetric random walk on $\{0,1,\dots,n\}$). What is the distribution of $\tilde{L}_n$?

```{r}
nsim <- 5000
n <- 10000
simlist <- numeric(nsim)
for (i in 1:nsim) {
  random_walk <- c(0, cumsum(sample(c(-1,1), size = n-1, replace = T)))
  simlist[i] = tail(which(random_walk == 0), 1)
}

hist(simlist)
```

The probability that the last zero occurs by time $tn$ for $0<t<n$ is approximately equal to the probability that the last zero for Brownian motion occurs by time $t$:

$$
P(\tilde{L}_n \le tn) \approx P(L_1 \le t) = \frac2\pi \arcsin\sqrt{t}
$$

since $P(L_t \le x) = \frac{2}{\pi} \arcsin \sqrt{\frac{x}{t}}$ for a Brownian motion on $(0, t)$.

## Example 8.10

Find the probability that Brownian motion with drift parameter $\mu = 0.6$ and variance $\sigma^2 = 0.25$ takes values between 1 and 3 at time $t=4$.

$$
P(1 \le X_4 \le 3) = P(1 \le 0.6(4) + \sqrt{0.25}B_4 \le 3) = P(1 \le 2.4 + 0.5B_4 \le 3) = P(-2.8 \le B_4 \le 1.2) = 0.645
$$

## Example 8.11

## Brownian Bridge

```{r}
nsteps <- 1000
nsim <- 5000
t <- seq(0, 1, length = nsteps)
bm <- c(0,cumsum(rnorm(nsteps-1,0,1)))/sqrt(nsteps)
brownian_bridge <- bm - t*bm[nsteps]
plot(t, brownian_bridge, type = "l")
```

## Mean and Variance of Geometric Brownian Motion

Let $G_t = G_0 e^{X_t}$ for $t \ge 0$ and $G_0 > 0$ with drift $\mu$ and variance $\sigma^2$. Then $\ln G_t = \ln G_0 + X_t$ is distributed Normally with mean $\ln G_0 + \mu t$ and variance $\sigma^2 t$.

$$
\begin{gathered}
E(G_t) = E(G_0 e^{X_t}) \\
= \int_{-\infty}^\infty G_0 e^x f_{X_t}(x) dx \\
= G_0 \int_{-\infty}^\infty \exp (x)\frac{1}{\sqrt{2\pi\sigma^2t}} \exp\left(-\frac{(x-\mu t)^2}{2\sigma^2t}\right) dx
\end{gathered}
$$

## Simulating Geometric Brownian Motion

```{r}
g0 <- 3
mu <- 0.4
sigma <- 0.6
nsim <- 10e3
n <- 1000
t <- seq(0, 1, length = n)
simlist <- numeric(n)
for (i in 1:nsim) {
  bm <- cumsum(c(0, rnorm(n-1, 0, 1))) / sqrt(n)
  simlist <- simlist + g0 * exp(mu * t + sigma * bm)
}
plot(simlist / nsim, type = "l")
```

## Example 8.15

Assume XYZ stock sells for \$80 and follows a geometric Brownian motion with drift 0.10 and volatility 0.50. Find the probability that in 90 days the price of XYZ will rise to ast least $100.

$$
\begin{gathered}
P(X_{0.25} \ge 100) = P(80e^{0.1(0.25) + 0.50B_{0.25}} \ge 100) \\
=P (e^{0.025 + 0.50B_{0.25}} \ge 1.25) \\
= P(0.025+0.50B_{0.25} \ge \ln1.25) \\
= P(B_{0.25} \ge (\ln 1.25 - 0.025) / 0.5) = 0.214
\end{gathered}
$$

# Exercises

## Exercise 8.1
Show that
$$
f(x,t) = \frac{1}{\sqrt{2\pi t}} e^{-x^2 /(2t)}
$$
satisfies the partial differential heat equation
$$
\frac{\partial f}{\partial t} = \frac{1}{2}\frac{\partial^2 f}{\partial x^2} 
$$

\soln Examining the first-order time partial differential:
$$
\begin{aligned}
\frac{\partial f}{\partial t} &= \frac{\partial}{\partial t} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{\sqrt{2\pi t}} \frac{\partial}{\partial t} \exp\left(-\frac{x^2}{2t}\right) + \exp\left(-\frac{x^2}{2t}\right) \frac{\partial}{\partial t} \frac{1}{\sqrt{2 \pi t}} \\
&= \frac{1}{\sqrt{2 \pi t}} \frac{-x^2}{2} \frac{-1}{t^2} \exp\left(-\frac{x^2}{2t}\right) + \exp\left(-\frac{x^2}{2t}\right) \frac{1}{\sqrt{2\pi}}\frac{-1}{2}{t^{-3/2}}
\\
&= \frac{1}{\sqrt{2\pi t}}\exp\left(-\frac{x^2}{2t}\right)\left[ \frac{x^2}{2t^2} -\frac{1}{2t}\right] \\
&= \frac{1}{2} \frac{1}{\sqrt{2\pi t}} \exp\left(-\frac{x^2}{2t}\right)\left[ \frac{x^2}{t^2} -\frac{1}{t}\right]
\end{aligned}
$$

The right side, which includes a second-order in $x$ term:
$$
\begin{aligned}
\frac{1}{2}\frac{\partial^2 f}{\partial x^2} &= \frac{1}{2} \frac{\partial^2}{\partial x^2} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \frac{\partial^2}{\partial x^2} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \frac{\partial}{\partial x} \frac{-2x}{2t}\exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \left[ \exp\left(-\frac{x^2}{2t}\right)\frac{\partial}{\partial x} \frac{-x}{t} -\frac{x}{t} \frac{\partial}{\partial x} \exp\left(-\frac{x^2}{2t}\right)\right] \\
&= \frac{1}{2}\frac{1}{\sqrt{2\pi t}} \left[-\frac{1}{t} \exp\left(-\frac{x^2}{2t}\right) + \frac{x^2}{t^2}\exp\left(-\frac{x^2}{2t}\right)\right] \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right)\left[\frac{x^2}{t^2}-\frac{1}{t}\right]
\end{aligned}
$$
These two sides are equal, thus $f(x,t)$ satisfies the heat equation.

## Exercise 8.2
For standard Brownian motion, find
(a) $P(B_2 \le 1)$

\soln $B_2$ is distributed Normal with mean 0 and variance 2, so $P(B_2 \le 1)$ = $\Phi\left(\frac{1}{\sqrt2}\right) \approx 0.760$

(b) $E(B_4 | B_1 = x)$

\soln By independent increments, $B_4-B_1$ and $B_1$ are independent random variables. By stationary increments, $B_4-B_1$ is distributed the same as $B_3$.

$$
E(B_4 | B_1 = x) = E(B_4-B_1 | B_1=x) +E(B_1|B_1=x) \\
= E(B_3) + x \\
= x
$$
(c) Corr$(B_{t+s},B_s)$

\soln
$$
\rm{Corr}(B_{t+s},B_s) = \frac{\rm{Cov}(B_{t+s},B_s)}{\sigma_{B_{t+s}} \sigma_{B_{s}}} = \frac{s}{\sqrt{t+s}\sqrt{s}} = \sqrt{\frac{s}{t+s}}
$$
(d) \Var$(B_4|B_1)$

\soln Let $X$ be the process from $t = 1$ to $4$. By stationary increments, $X = B_4 - B_1$ has the same distribution as $B_3$ and by independent increments, is uncorrelated with $B_1$.
$$
\rm{Var}(B_4|B_1) = \rm{Var}(B_1 + X| B_1) =0 + \rm{Var}(X) = 3
$$
(e) $P(B_3 \le 5|B_1=2)$

\soln By the Markov property, the Wiener process restarts at $t=1$. Thus, we can calculate the unconditional probability for the event $W_2 \le 3$, where $W$ is a standard Wiener process.
$$
P(B_3 \le 5|B_1=2) = P(W_2 \le 3) = \Phi\left(\frac{3}{\sqrt{2}}\right)
$$

## Exercise 8.3
For standard Brownian motion started at $x = -3$, find
(a) $P(X_1+X_2 >-1)$

\soln Consider the process $X_t$, where $t > 0$. This is distributed equal to a standard Brownian motion process but shifted down by $3$, so $X_t = B_t - 3$. Then, we can rewrite $X_2$ as $B_2 - 3$ which is distributed $(B_2-B_1) + B_1 - 3$.

$$
P(X_1 + X_2 > -1) = P(B_1 - 3 + (B_2-B_1)+B_1 - 3 > -1) = P(2B_1 + (B_2-B_1) - 6 > -1) \\
= P(2B_1 + (B_2-B_1) > 5)
$$

By stationary intervals, $(B_2-B_1)$ is distributed Gaussian with variance 1. $2B_1 + (B_2-B_1)$ is distributed $2X+Y$, where $X$ and $Y$ are both standard Normal random variables, so $2B_1 + (B_2-B_1) \sim \mathcal{N}(0, 5)$. Therefore, $P(X_1+X_2 >-1) = 1 - \Phi(\sqrt{5})$, which is approximately 0.013.

(b) The conditional density of $X_2$ given $X_1=0$

\soln $X_2$ is distributed like $X_1 + B_1$ by stationary and independent increments, so we have:
$$
X_2 | X_1 = 0 \\
\Rightarrow X_1 + B_1 | X_1 = 0 \\
\Rightarrow B_1
$$

The conditional density of $X_2 \mid X_1 = 0$ is a standard Normal with variance 1. Intuitively, this makes sense. By independent increments, the process on the interval $t=1$ to $t=2$ is a new Brownian motion process restarted at the origin.

(c) Cov$(X_3,X_4)$

\soln 
$$
\rm{Cov}(X_3, X_4) = \rm{Cov}(B_3 -3 , B_4 - 4) = \rm{Cov}(B_3, B_4) = 3
$$

(d) $E(X_4|X_1)$

\soln By independence and stationary increments, $X_4$ is distributed $X_1 + B_3$.
$$
E(X_4 | X_1) = E(X_1|X_1) + E(B_3) = X_1 + 0 = X_1
$$

Intuitively, the most recent information we have at $t=4$ is the value of the process at $t=1$. The process restarts at $t=1$, so the conditional expectation is the given value $X_1$. This is in line with the process's martingale property.

## Exercise 8.4
In a race between Lisa and Cooper, let $X_t$ denote the amount of time (in seconds) by which Lisa is ahead when $100t$ percent of the race has been completed. Assume that $(X_t)_{0\le t \le 1}$ can be modeled by a Brownian motion with drift parameter 0 and variance parameter $\sigma^2$. If Lisa is leading by $\sigma / 2$ seconds after three-fourths of the race is complete, what is the probability that she is the winner?

\soln The desired probability is $P(X_1 \ge 0 | X_{0.75} = \sigma / 2)$. The race process can be rewritten as $X_1 = (X_1 - X_{0.75}) + X_{0.75}$. By stationary increments, $X_1 - X_{0.75} \sim \sigma B_{0.25}$ and by independent increments, is uncorrelated with the process $X_{0.75}$.

$$
\begin{aligned}
P(X_1 \ge 0 | X_{0.75} = \sigma / 2) &= P((X_1 - X_{0.75}) + X_{0.75} > 0 | X_{0.75} = \sigma/2) \\
&= P(\sigma B_{0.25} + X_{0.75} > 0 | X_{0.75} = \sigma / 2) \\
&= P(\sigma B_{0.25} + \sigma / 2 > 0) \\
&= P(B_{0.25} > -1/2) \\
&= P(1/2 \cdot Z > -1/2) \\
&= 1 - \Phi(-1) \\
&= \Phi(1)
\end{aligned}
$$

This is approximately 0.841.

## Exercise 8.5

Consider standard Brownian motion. Let $0 < s < t$.

(a) Find the joint density of $(B_s,B_t)$

\soln Because $B_t$ is a standard Brownian motion process, $B_s$ and $B_t$ have a multivariate Normal distribution. $\vec\mu = (0, 0)^T$ and the covariance matrix is:
$$
\Cov(B_s,B_t) = \begin{bmatrix}
s & s \\
s & t
\end{bmatrix}
$$

(b) Show that the conditional distribution of $B_s$ given $B_t = y$ is Normal, with mean and variance
$$
E(B_s|B_t=y) = \frac{sy}{t} \quad\text{and} \, \Var(B_s|B_t=y)=\frac{s(t-s)}{t}
$$

\soln Because $(B_s, B_t)$ is a bivariate Normal random variable, it follows that the conditional distribution $B_s|B_t=y$ is Normal. We can rewrite $B_t = B_s + (B_t-B_s)$, and setting $B_s = x$, we have:
$$
f_{B_s | B_t = y}(x | y) = \frac{f_{B_s,B_t}(x,y)}{f_{B_t=y}(y)}
$$
