---
title: "Chapter 8: Brownian Motion"
output: pdf_document
date: '2022-05-30'
---
\newcommand{\Var}{\textrm{Var}}
\newcommand{\Cov}{\textrm{Cov}}
\newcommand{\soln}{\textbf{Solution:}}
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

```{r brownian, eval=FALSE, include=FALSE}
wiener_process <- function(t) {
  # time t
  # steps n
  n <- 1000
  bm <- c(0, cumsum(rnorm(n, 0, sqrt(t/n))))
  steps <- seq(0,t,length = n+1)
  bm
}
```

# Examples
## Example 8.1

For $0 < s < t$, find the distribution of $B_s + B_t$.
$$
B_s + B_t = B_s + B_s + B_t - B_s = 2B_s + (B_t - B_s)
$$

By independent increments, $B_s$ and $B_t - B_s$ are independent random variables.
$$
\begin{gathered}
E(B_s + B_t) = E(B_s) + E(B_t) = 0 \\
\Var(B_s + B_t) = \Var(2B_s + (B_t - B_s)) = 4Var(B_s) + \Var(B_t-B_s) \\
= 4s + t-s \\
= 3s+t
\end{gathered}
$$

Therefore, $B_s + B_t \sim \mathcal{N}(0, 3s+t)$.

## Example 8.2

If a standard Brownian motion particle is at position 1 at time 2, find the probability that the position is at most 3 at time 5.

By stationary increments, $B_5 - B_2 \sim B_3$.
$$
P(B_5 \le 3 \mid B_2 = 1) = P(B_5 - B_2 \le 3 - B_2 \mid B_2 = 1) \\
= P(B_5 - B_2 \le 2) \\
= P(B_3 \le 2) = 0.876
$$

## Example 8.3

Find the covariance of $B_s$ and $B_t$.

$$
\Cov(B_s, B_t) = E(B_sB_t) - E(B_s)E(B_t) = E(B_sB_t)
$$

Assuming that $s < t$:

$$
\begin{gathered}
B_t = B_s + (B_t - B_s) \\
E(B_sB_t) = E(B_s(B_s + (B_t - B_s))) \\
= E(B_s^2 + B_s(B_t - B_s)) \\
= E(B_s^2) + E(B_s(B_t-B_s)) \\
=\Var(B_s) + E(B_s)E(B_t-B_s) \\
=s + 0 = s
\end{gathered}
$$

By symmetry, if $t < s$, then $\Cov(B_sB_t) = t$. In general, $\Cov(B_sB_t) = \min(s, t)$.

## Example 8.4

For a simple symmetric random walk, consider the maximum of the walk in the first $n$ steps. Let $g(f) = \max_{0 \le t \le 1} f(t)$.

By the invariance principle, $g(S_{nt} / \sqrt{n}) \approx g(B_t)$ for large $n$. 

$$
\lim_{n\rightarrow\infty} g\left(\frac{S_{nt}} {\ \sqrt{n}}\right) =  \lim_{n \rightarrow \infty} \max_{0 \le t \le 1} \left(\frac{S_{nt}}{\sqrt{n}}\right) = \lim_{n\rightarrow\infty} \max_{0 \le k \le n}\left(\frac{S_k}{\sqrt{n}}\right)
$$

This converges to $g(B_t) = \max_{0\le t \le 1}(B_t)$ in the limit. 

$$
\begin{gathered}
\max_{0 \le k \le n} S_k / \sqrt{n} = \max_{0\le t \le 1}(B_t) \\
\max_{0\le k\le n} S_k = \sqrt{n} \max_{0 \le t \le 1} (B_t)
\end{gathered}
$$

$\max_{0\le t \le 1}(B_t)$ has density $f(x) = \sqrt{2/\pi}\exp({-x^2/2})$ for $x > 0$. If $n = 10,000$ steps, the probability that a value greater than 200 is reached is:

$$
P\left(\max_{0 \le k \le n}S_k > 200\right) \\
= P\left(\max_{0 \le k \le n}\frac{S_k}{100} > 2\right) \\
= P\left(\max_{0 \le k \le n}\frac{S_k}{\sqrt{n}} > 2\right) \\
= P(M > 2) = 0.0455
$$

```{r}
# simulating a random walk with 10000 steps
n <- 10000
nsim <- 10000
sim <- replicate(nsim,
                 max(cumsum(sample(size=n, c(-1,1), replace = T))))

mean(sim)
sd(sim)

sim <- replicate(nsim,
                 ifelse(max(cumsum(sample(c(-1, 1), n, replace = T))) > 200, 1, 0))

mean(sim)
```

## Example 8.5

For $a>0$, let $X_t = B_{at}/\sqrt{a}$ for $t \ge 0$. Show that $X_t$ is a standard Brownian motion.

The linear combination of $X_k$ for $0 \le t_1 < \dots < t_k$ is 

$$
\sum_{i=1}^k a_iX_{t_i} = \sum_{i=1}^k \frac{a_i}{\sqrt{a}}B_{at}
$$

This has a univariate Normal distribution since $B_{at}$ is a standard Brownian motion process and is thus a Gaussian process. $X_0 = 0$ since $B_0 = 0$. The mean function is:
$$
E(X_t) = E(B_{at} / \sqrt{a}) = 0
$$

The covariance is:
$$
\begin{gathered}
\Cov(X_s, X_t) = \Cov(B_{as} / \sqrt{a}, B_{at} / \sqrt{a}) \\
= \frac{1}{a}\Cov(B_{as}, B_{at}) \\
= \frac1a \min(as, at) = min(s, t)
\end{gathered}
$$

Finally, because $B_t$ is path continuous, $X_t$ is path continuous for all $a>0$.

## Example 8.6

Let $(X_t)_{t \ge 0}$ be a Brownian motion process started at $x=3$. Find $P(X_2 > 0)$.

Write $X_t = B_t + 3$. Then,

$$
P(X_2 > 0) = P(B_2 + 3 > 0) = P(B_2 > -3) = 0.983
$$

## Example 8.7

A particle moves according to Brownian motion started at $x=1$. After $t=3$ hours, the particle is at level 1.5. Find the probability that the particle reaches level 2 sometime in the next hour. 

The translated process is a Brownian motion process started at $x=1.5$. The event that the translated process hits level 2 within the next hour is equal to the event that a standard Brownian motion process hits $x = 2-1.5 = 0.5$ within the next hour.

$$
P(T_{0.5} < 1) = \int_0^1 f_{T_{0.5}}(t) \, dt
= \int_0^1 \frac{0.5}{\sqrt{2\pi t^3}} e^{-0.5^2 / 2t} \, dt = 0.617
$$

## Example 8.8

A laboratory instrument takes annual temperature measurements. Measurement errors are assumed to be independent and Normally distributed. As precision decreases over time, errors are modeled as standard Brownian motion. for how many years can the lab be guaranteed that there is at least 90\% probability that errors are less than 4 degrees?

Let $B_t$ be the error at time $t$. Find $t$ such that $P(M_t < 4) \ge 90\%$.

$$
0.9 \le P(M_t < 4) = 1 -P(M_t \ge 4) = 1-2P(B_t \ge 4) = 2P(B_t < 4) - 1
$$

This yields

$$
0.95 \le P(B_t < 4) = P\left(Z \le \frac{4}{\sqrt t}\right)
$$

The 95th percentile of the standard Normal distribution is 1.645:

$$
\begin{gathered}
1.645 = \frac{4}{\sqrt{t}} \\
t = \left(\frac{4}{1.645}\right)^2 = 5.91
\end{gathered}
$$

## Last Even Time

Flip a coin $n=10,000$ times. If heads, A pays B \$1, otherwise if tails, B pays A. Let $\tilde{L}_n$ be the last time in $n$ times that the players are tied (aka the last zero in a simple symmetric random walk on $\{0,1,\dots,n\}$). What is the distribution of $\tilde{L}_n$?

```{r}
nsim <- 5000
n <- 10000
simlist <- numeric(nsim)
for (i in 1:nsim) {
  random_walk <- c(0, cumsum(sample(c(-1,1), size = n-1, replace = T)))
  simlist[i] = tail(which(random_walk == 0), 1)
}

hist(simlist)
```

The probability that the last zero occurs by time $tn$ for $0<t<n$ is approximately equal to the probability that the last zero for Brownian motion occurs by time $t$:

$$
P(\tilde{L}_n \le tn) \approx P(L_1 \le t) = \frac2\pi \arcsin\sqrt{t}
$$

since $P(L_t \le x) = \frac{2}{\pi} \arcsin \sqrt{\frac{x}{t}}$ for a Brownian motion on $(0, t)$.

## Example 8.10

Find the probability that Brownian motion with drift parameter $\mu = 0.6$ and variance $\sigma^2 = 0.25$ takes values between 1 and 3 at time $t=4$.

$$
P(1 \le X_4 \le 3) = P(1 \le 0.6(4) + \sqrt{0.25}B_4 \le 3) = P(1 \le 2.4 + 0.5B_4 \le 3) = P(-2.8 \le B_4 \le 1.2) = 0.645
$$

## Example 8.11

## Brownian Bridge

```{r}
nsteps <- 1000
nsim <- 5000
t <- seq(0, 1, length = nsteps)
bm <- c(0,cumsum(rnorm(nsteps-1,0,1)))/sqrt(nsteps)
brownian_bridge <- bm - t*bm[nsteps]
plot(t, brownian_bridge, type = "l")
```

## Mean and Variance of Geometric Brownian Motion

Let $G_t = G_0 e^{X_t}$ for $t \ge 0$ and $G_0 > 0$ with drift $\mu$ and variance $\sigma^2$. Then $\ln G_t = \ln G_0 + X_t$ is distributed Normally with mean $\ln G_0 + \mu t$ and variance $\sigma^2 t$.

$$
\begin{gathered}
E(G_t) = E(G_0 e^{X_t}) \\
= \int_{-\infty}^\infty G_0 e^x f_{X_t}(x) dx \\
= G_0 \int_{-\infty}^\infty \exp (x)\frac{1}{\sqrt{2\pi\sigma^2t}} \exp\left(-\frac{(x-\mu t)^2}{2\sigma^2t}\right) dx
\end{gathered}
$$

## Simulating Geometric Brownian Motion

```{r}
g0 <- 3
mu <- 0.4
sigma <- 0.6
nsim <- 10e3
n <- 1000
t <- seq(0, 1, length = n)
simlist <- numeric(n)
for (i in 1:nsim) {
  bm <- cumsum(c(0, rnorm(n-1, 0, 1))) / sqrt(n)
  simlist <- simlist + g0 * exp(mu * t + sigma * bm)
}
plot(simlist / nsim, type = "l")
```

## Example 8.15

Assume XYZ stock sells for \$80 and follows a geometric Brownian motion with drift 0.10 and volatility 0.50. Find the probability that in 90 days the price of XYZ will rise to ast least $100.

$$
\begin{gathered}
P(X_{0.25} \ge 100) = P(80e^{0.1(0.25) + 0.50B_{0.25}} \ge 100) \\
=P (e^{0.025 + 0.50B_{0.25}} \ge 1.25) \\
= P(0.025+0.50B_{0.25} \ge \ln1.25) \\
= P(B_{0.25} \ge (\ln 1.25 - 0.025) / 0.5) = 0.214
\end{gathered}
$$

# Exercises

## Exercise 8.1
Show that
$$
f(x,t) = \frac{1}{\sqrt{2\pi t}} e^{-x^2 /(2t)}
$$
satisfies the partial differential heat equation
$$
\frac{\partial f}{\partial t} = \frac{1}{2}\frac{\partial^2 f}{\partial x^2} 
$$

\soln Examining the first-order time partial differential:
$$
\begin{aligned}
\frac{\partial f}{\partial t} &= \frac{\partial}{\partial t} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{\sqrt{2\pi t}} \frac{\partial}{\partial t} \exp\left(-\frac{x^2}{2t}\right) + \exp\left(-\frac{x^2}{2t}\right) \frac{\partial}{\partial t} \frac{1}{\sqrt{2 \pi t}} \\
&= \frac{1}{\sqrt{2 \pi t}} \frac{-x^2}{2} \frac{-1}{t^2} \exp\left(-\frac{x^2}{2t}\right) + \exp\left(-\frac{x^2}{2t}\right) \frac{1}{\sqrt{2\pi}}\frac{-1}{2}{t^{-3/2}}
\\
&= \frac{1}{\sqrt{2\pi t}}\exp\left(-\frac{x^2}{2t}\right)\left[ \frac{x^2}{2t^2} -\frac{1}{2t}\right] \\
&= \frac{1}{2} \frac{1}{\sqrt{2\pi t}} \exp\left(-\frac{x^2}{2t}\right)\left[ \frac{x^2}{t^2} -\frac{1}{t}\right]
\end{aligned}
$$

The right side, which includes a second-order in $x$ term:
$$
\begin{aligned}
\frac{1}{2}\frac{\partial^2 f}{\partial x^2} &= \frac{1}{2} \frac{\partial^2}{\partial x^2} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \frac{\partial^2}{\partial x^2} \exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \frac{\partial}{\partial x} \frac{-2x}{2t}\exp\left(-\frac{x^2}{2t}\right) \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \left[ \exp\left(-\frac{x^2}{2t}\right)\frac{\partial}{\partial x} \frac{-x}{t} -\frac{x}{t} \frac{\partial}{\partial x} \exp\left(-\frac{x^2}{2t}\right)\right] \\
&= \frac{1}{2}\frac{1}{\sqrt{2\pi t}} \left[-\frac{1}{t} \exp\left(-\frac{x^2}{2t}\right) + \frac{x^2}{t^2}\exp\left(-\frac{x^2}{2t}\right)\right] \\
&= \frac{1}{2} \frac{1}{\sqrt{2 \pi t}} \exp\left(-\frac{x^2}{2t}\right)\left[\frac{x^2}{t^2}-\frac{1}{t}\right]
\end{aligned}
$$
These two sides are equal, thus $f(x,t)$ satisfies the heat equation.

## Exercise 8.2
For standard Brownian motion, find
(a) $P(B_2 \le 1)$

\soln $B_2$ is distributed Normal with mean 0 and variance 2, so $P(B_2 \le 1)$ = $\Phi\left(\frac{1}{\sqrt2}\right) \approx 0.760$

(b) $E(B_4 | B_1 = x)$

\soln By independent increments, $B_4-B_1$ and $B_1$ are independent random variables. By stationary increments, $B_4-B_1$ is distributed the same as $B_3$.

$$
E(B_4 | B_1 = x) = E(B_4-B_1 | B_1=x) +E(B_1|B_1=x) \\
= E(B_3) + x \\
= x
$$
(c) Corr$(B_{t+s},B_s)$

\soln
$$
\rm{Corr}(B_{t+s},B_s) = \frac{\rm{Cov}(B_{t+s},B_s)}{\sigma_{B_{t+s}} \sigma_{B_{s}}} = \frac{s}{\sqrt{t+s}\sqrt{s}} = \sqrt{\frac{s}{t+s}}
$$
(d) \Var$(B_4|B_1)$

\soln Let $X$ be the process from $t = 1$ to $4$. By stationary increments, $X = B_4 - B_1$ has the same distribution as $B_3$ and by independent increments, is uncorrelated with $B_1$.
$$
\rm{Var}(B_4|B_1) = \rm{Var}(B_1 + X| B_1) =0 + \rm{Var}(X) = 3
$$
(e) $P(B_3 \le 5|B_1=2)$

\soln By the Markov property, the Wiener process restarts at $t=1$. Thus, we can calculate the unconditional probability for the event $W_2 \le 3$, where $W$ is a standard Wiener process.
$$
P(B_3 \le 5|B_1=2) = P(W_2 \le 3) = \Phi\left(\frac{3}{\sqrt{2}}\right)
$$

## Exercise 8.3
For standard Brownian motion started at $x = -3$, find
(a) $P(X_1+X_2 >-1)$

\soln Consider the process $X_t$, where $t > 0$. This is distributed equal to a standard Brownian motion process but shifted down by $3$, so $X_t = B_t - 3$. Then, we can rewrite $X_2$ as $B_2 - 3$ which is distributed $(B_2-B_1) + B_1 - 3$.

$$
P(X_1 + X_2 > -1) = P(B_1 - 3 + (B_2-B_1)+B_1 - 3 > -1) = P(2B_1 + (B_2-B_1) - 6 > -1) \\
= P(2B_1 + (B_2-B_1) > 5)
$$

By stationary intervals, $(B_2-B_1)$ is distributed Gaussian with variance 1. $2B_1 + (B_2-B_1)$ is distributed $2X+Y$, where $X$ and $Y$ are both standard Normal random variables, so $2B_1 + (B_2-B_1) \sim \mathcal{N}(0, 5)$. Therefore, $P(X_1+X_2 >-1) = 1 - \Phi(\sqrt{5})$, which is approximately 0.013.

(b) The conditional density of $X_2$ given $X_1=0$

\soln $X_2$ is distributed like $X_1 + B_1$ by stationary and independent increments, so we have:
$$
X_2 | X_1 = 0 \\
\Rightarrow X_1 + B_1 | X_1 = 0 \\
\Rightarrow B_1
$$

The conditional density of $X_2 \mid X_1 = 0$ is a standard Normal with variance 1. Intuitively, this makes sense. By independent increments, the process on the interval $t=1$ to $t=2$ is a new Brownian motion process restarted at the origin.

(c) Cov$(X_3,X_4)$

\soln 
$$
\rm{Cov}(X_3, X_4) = \rm{Cov}(B_3 -3 , B_4 - 4) = \rm{Cov}(B_3, B_4) = 3
$$

(d) $E(X_4|X_1)$

\soln By independence and stationary increments, $X_4$ is distributed $X_1 + B_3$.
$$
E(X_4 | X_1) = E(X_1|X_1) + E(B_3) = X_1 + 0 = X_1
$$

Intuitively, the most recent information we have at $t=4$ is the value of the process at $t=1$. The process restarts at $t=1$, so the conditional expectation is the given value $X_1$. This is in line with the process's martingale property.

## Exercise 8.4
In a race between Lisa and Cooper, let $X_t$ denote the amount of time (in seconds) by which Lisa is ahead when $100t$ percent of the race has been completed. Assume that $(X_t)_{0\le t \le 1}$ can be modeled by a Brownian motion with drift parameter 0 and variance parameter $\sigma^2$. If Lisa is leading by $\sigma / 2$ seconds after three-fourths of the race is complete, what is the probability that she is the winner?

\soln The desired probability is $P(X_1 \ge 0 | X_{0.75} = \sigma / 2)$. The race process can be rewritten as $X_1 = (X_1 - X_{0.75}) + X_{0.75}$. By stationary increments, $X_1 - X_{0.75} \sim \sigma B_{0.25}$ and by independent increments, is uncorrelated with the process $X_{0.75}$.

$$
\begin{aligned}
P(X_1 \ge 0 | X_{0.75} = \sigma / 2) &= P((X_1 - X_{0.75}) + X_{0.75} > 0 | X_{0.75} = \sigma/2) \\
&= P(\sigma B_{0.25} + X_{0.75} > 0 | X_{0.75} = \sigma / 2) \\
&= P(\sigma B_{0.25} + \sigma / 2 > 0) \\
&= P(B_{0.25} > -1/2) \\
&= P(1/2 \cdot Z > -1/2) \\
&= 1 - \Phi(-1) \\
&= \Phi(1)
\end{aligned}
$$

This is approximately 0.841.

## Exercise 8.5

Consider standard Brownian motion. Let $0 < s < t$.

(a) Find the joint density of $(B_s,B_t)$

\soln Because $B_t$ is a standard Brownian motion process, $B_s$ and $B_t$ have a multivariate Normal distribution. $\vec\mu = (0, 0)^T$ and the covariance matrix is:
$$
\Cov(B_s,B_t) = \begin{bmatrix}
s & s \\
s & t
\end{bmatrix}
$$

(b) Show that the conditional distribution of $B_s$ given $B_t = y$ is Normal, with mean and variance
$$
E(B_s|B_t=y) = \frac{sy}{t} \quad\text{and} \, \Var(B_s|B_t=y)=\frac{s(t-s)}{t}
$$

\soln Because $(B_s, B_t)$ is a bivariate Normal random variable, it follows that the conditional distribution $B_s|B_t=y$ is Normal. We can rewrite $B_t = B_s + (B_t-B_s)$, and setting $B_s = x$, we have:

$$
\begin{gathered}
f_{B_s|B_t}(x|y) = \frac{f_{B_t|B_s}(y|x)f_{B_s}(x)}{f_{B_t}(y)} \\
= \frac{\sqrt{2\pi t}}{\sqrt{2\pi(t-s)} \cdot \sqrt{2\pi s}} \cdot  \exp\left(-\frac{(y-x)^2}{2(t-s)}  -\frac{x^2}{2s} + \frac{y^2}{2t}\right) \\
= \frac{1}{\sqrt{2 \pi s(t-s)/t}} \cdot \exp \left(-\frac{st(y^2-2xy+x^2)+t(t-s)x^2-s(t-s)y^2}{2st(t-s)}\right) \\
= \frac{1}{\sqrt{2 \pi s(t-s)/t}} \cdot \exp \left(-\frac{sty^2-2stxy+stx^2+t^2x^2-stx^2-sty^2+s^2y^2}{2st(t-s)}\right) \\
= \frac{1}{\sqrt{2 \pi s(t-s)/t}} \cdot \exp \left(-\frac{t^2x^2-2stxy+s^2y^2}{2st(t-s)}\right) \\
= \frac{1}{\sqrt{2 \pi s(t-s)/t}} \cdot \exp \left(-\frac{(tx-sy)^2}{2st(t-s)}\right) \\
= \frac{1}{\sqrt{2 \pi s(t-s)/t}} \cdot \exp \left(-\frac{(x-\frac{s}{t}y)^2}{2s(t-s)/t}\right)
\end{gathered}
$$
This corresponds to the density for a Normal random variable with mean $\frac{sy}{t}$ and standard deviation $\frac{s}{t}(t-s)$.

## Exercise 8.6
For $s > 0$, show that the translation $(B_{t+s} - B_s)_{t\ge0}$ is a standard Brownian motion.

\soln To show that $X_t = (B_{t+s} - B_s)_{t\ge0}$ is a standard Brownian motion, we must show the initial value $X_0 = 0$, the mean function is $0$ for all $t$, the covariance between any 2 times $s$ and $t$ is min$(s,t)$, and the function is continuous with probability 1.

Initial value: $X_0 = B_{0+s}-B_s = B_s - B_s = 0$.

Mean function: 
$$
E(X_t) = E(B_{t+s} - B_s) = E(B_{t+s}) - E(B_s) = 0 - 0 = 0
$$

Covariance function: Let $0 < t < u$.
$$
\Cov(X_t,X_u) = \Cov(B_{t+s} - B_s, B_{u+s}-B_s) \\
= \Cov(B_{t+s},B_{u+s})-\Cov(B_{t+s},B_{s})-\Cov(B_s,B_{u+s})+\Cov(B_s,B_s) \\
= \min(t+s,u+s) - \min(t+s, s) - \min(s, u+s) + s \\
= (t+s)- (s) - (s) + (s) \\
= t = \min(t,u)
$$

Continuity: The last condition is true because the difference of 2 functions that are almost surely continuous is also almost surely continuous.

As all of the conditions are met, $X_t$ is a standard Brownian motion process.

## Exercise 8.7
Show that the reflection $(-B_t)_{t\ge0}$ is a standard Brownian motion.

\soln Let $X_t = -B_t$ for $t \ge 0$.

Initial value: $X_0 = -B_0 = 0$.

Mean value: $E(X_t) = E(-B_t) = -E(B_t) = 0$.

Covariance function: Let $0 < s < t$. $\Cov(X_s,X_t) = \Cov(-B_s,-B_t) = \Cov(B_s,B_t) = \min(s,t)$.

Continuity: Continuity is inherited by inspection.

As all of the conditions are met, $X_t$ is a standard Brownian motion process.

## Exercise 8.8
Find the covariance function for Brownian motion with drift.

\soln Let $X_t = \mu t + \sigma B_t$. Let $0<s<t$. The covariance function is:
$$
\begin{aligned}
\Cov(X_s,X_t) &= \Cov(\mu s + \sigma B_s, \mu t + \sigma B_t \\
&= \Cov(\sigma B_s,\sigma B_t) \\
&= \sigma^2 \Cov(B_s, B_t) \\
&= \sigma^2 s
\end{aligned}
$$

## Exercise 8.9
Let $W_t = B_{2t} - B_t$, for $t \ge 0$.

(a) Is $(W_t)_{t\ge0}$ a Gaussian process?

\soln $W_t$ is a Gaussian process as $B_{2t}$ and $B_t$ are both Gaussian processes, and the difference of two Gaussian processes is Gaussian. We can see that at each time $t$, $B_{2t}$ and $B_t$ are distributed Normal, so $W_t$ is Normal at each time $t$.

(b) Is $(W_t)_{t\ge0}$ a Brownian motion process?

\soln $W_t$ is not a Brownian motion process. We look at the covariance function:
$$
\begin{aligned}
\Cov(W_s,W_t) &= \Cov(B_{2s}-B_s,B_{2t}-B_t) \\
&= \Cov(B_{2s},B_{2t}) - \Cov(B_{s},B_{2t}) - \Cov(B_{2s},B_{t}) + \Cov(B_{s},B_{t}) \\
&= 2\min(s,t) - \min(s,2t) - \min(2s,t) + \min(s,t) \\
&= 3 \min(s,t) - \min(s,2t) - \min(2s,t)
\end{aligned}
$$

This expression cannot be further simplified, and does not collapse to $\min(s,t)$ unless $s = t$. This is not standard Brownian motion.

## Exercise 8.10
Let $(B_t)_{t\ge0}$ be a Brownian motion started in $x$. Let
$$
X_t = B_t - t(B_1-y),\textrm{ for }0\le t \le 1
$$
The process $(X_t)_{t\ge0}$ is a Brownian bridge with start in $x$ and end in $y$. Find the mean and covariance functions.

\soln The mean function is $E(X_t) = E(B_t - t(B_1-y)) = E(B_t) - tE(B_1) + ty = x - tx + ty = (1-t)x + ty$. The mean varies linearly between $x$ and $y$ over the interval $0 \le t \le 1$.

The covariance function is:
$$
\begin{aligned}
\Cov(X_s,X_t) &= \Cov(B_s-s(B_1-y), B_t-t(B_1-y)) \\
&= \Cov(B_s,B_t) + \Cov(B_s,-t(B_1-y)) + \Cov(-s(B_1-y),B_t) + \Cov(-s(B_1-y), -t(B_1-y)) \\
&= \Cov(B_s,B_t) + \Cov(B_s,-tB_1) + \Cov(-sB_1,B_t) + \Cov(-sB_1,-tB_1) \\
&= \min(s,t) -ts - st + st \\
&= \min(s,t) - st
\end{aligned}
$$

When $s,t$ are both small, then the covariance looks similar to standard Brownian motion. This is akin to the process just starting out, and the influence of the correction term is small. As $s,t$ grow, then the covariance is reduced as the bridge term contributes more as time progresses.

## Exercise 8.11
A standard Brownian motion crosses the $t$-axis at times $t=2$ and $t=5$. Find the probability that the process exceeds level $x=1$ at time $t = 4$.

\soln Due to the Markov property and by shifting the process, the event $\{B_4 > 1 | B_2 = 0, B_5 = 0\}$ is equivalent to $\{W_2 > 1\}$, where $W_t = B_t - \frac{t}{3}B_3$ is a Brownian bridge with ends tied down to 0 and $0 \le t \le 3$. The mean of this process is 0, and at each time $t$, the variance is:
$$
\begin{aligned}
\Var(W_t) &= \Var\left(B_t-\frac{t}{3}B_3\right) \\
&= \Var(B_t) + \frac{t^2}{9}\Var(B_3) - 2\cdot \frac{t}{3}\Cov(B_t,B_3) \\
&= t + \frac{3t^2}{9} - \frac{2t^2}{3} \\
&= t-\frac{t^2}{3} \\
&= t\left(1-\frac{t}{3}\right)
\end{aligned}
$$

So at time $t=2$, $W_2 \sim \mathcal{N}\left(0, 2\left(1-\frac{2}{3}\right)\right)$. The standard deviation is $\sqrt{2/3}$, so:
$$
P(W_2 > 1) = 1 - \Phi\left(\frac{1}{\sqrt{2/3}}\right) = 1 - \Phi\left(\sqrt{\frac32}\right) \approx 0.110
$$

```{r exercise_11, eval=FALSE, include=FALSE}
exercise_11 <- function() {
  # brownian bridge:
  bm <- wiener_process(3)
  ts <- seq(0, 3, length = 1001)
  brownian_bridge <- bm - ts / 3 * bm[length(ts)]
  idx <- length(ts)*2/3 # pluck the t=2
  brownian_bridge[idx] > 1
}

mean(replicate(1000, exercise_11()))
1- pnorm(sqrt(3/2))
```

## Exercise 8.12
Show that Brownian motion with drift has independent and stationary increments.

\soln Let $X_t = \mu t + \sigma B_t$ be the drift process.

Stationary increments: We show that for all $s,t > 0$, $X_{t+s}-X_s$ has the same distribution as $X_t$.
$$
\begin{aligned}
X_{t+s}-X_s &= \mu(t+s) + \sigma B_{t+s} - \left[\mu s + \sigma B_s\right] \\
&= \mu t + \sigma (B_{t+s}-B_s) \\
&= \mu t + \sigma B_t
\end{aligned}
$$
The last equality is a property of standard Brownian motion. This is the same distribution as $X_t$, so the drift process exhibits stationary increments.

Independent increments: We show that for $0 \le q < r \le s < t$, $X_t - X_s$ and $X_r-X_q$ are independent random variables.
$$
\begin{aligned}
\Cov(X_t-X_s, X_r-X_q) &= \Cov(X_t,X_r) - \Cov(X_s,X_r) - \Cov(X_t,X_q) + \Cov(X_s,X_q) \\
&= \sigma^2 \left[ \min(t,r) - \min(s,r) - \min(t,q) + \min(s,q)\right] \\
&= \sigma^2 \left[ r - r - q +q\right] \\
&= 0
\end{aligned}
$$
Each non-overlapping interval is uncorrelated, so the drift process exhibits independent increments.

## Exercise 8.13
Let $(X_t)_{t\ge0}$ denote a Brownian motion with drift $\mu$ and variance $\sigma^2$. For $0<s<t$, find $E(X_sX_t)$.

\soln By definition, $\Cov(X_s,X_t) = E(X_sX_t)-E(X_s)E(X_t)$, so $E(X_sX_t) = \Cov(X_s,X_t) + E(X_s)E(X_t) = \sigma^2 \min(s,t) + (\mu t)(\mu s) = \sigma^2 s + \mu^2 st = s(\sigma^2s + \mu^2 t)$.

## Exercise 8.14
A Brownian motion with drift parameter $\mu = -1$ and variance $\sigma^2 = 4$ starts at $x=1.5$. Find the probability that the process is positive at $t=3$.

\soln Let $X_t = -t + 2 B_t + 1.5$, where $B_t$ is a standard Brownian motion started at the origin. This corresponds to the drift process in the problem statement.
$$
P(X_3 > 0) = P(-3 + 2B_3+1.5 > 0) = P(2B_3 > 3-1.5) = P\left(B_3 > \frac{3}{4}\right)
$$
Because $B_3 \sim \sqrt{3} Z$, this probability is $1-\Phi\left(\frac{3}{4\sqrt{3}}\right) = \Phi\left(-\frac{\sqrt{3}}{4}\right) \approx 0.097$.

```{r exercise_14, eval=FALSE, include=FALSE}
exercise_14 <- function() {
  bm <- wiener_process(3)
  ts <- seq(0, 3, length = 1001)
  drift_process <- 2 * (bm) + 1.5 - 1 * ts
  drift_process[length(ts)] > 0
}

mean(replicate(10000, exercise_14()) > 0)
```

## Exercise 8.15

See Example 8.11 on using Brownian motion to model the home team advantage in basketball. In Stern (1994), Table 8.3 is given based on the outcomes of 493 basketball games played in 1992.

| Quarter 	| Variable          	| Mean 	| Standard Deviation 	|   	|
|---------	|-------------------	|------	|--------------------	|---	|
| 1       	| $X_{0.25}$        	| 1.41 	| 7.58               	|   	|
| 2       	| $X_0.50 - X_0.25$ 	| 1.57 	| 7.40               	|   	|
| 3       	| $X_0.75 - X_0.50$ 	| 1.51 	| 7.30               	|   	|
| 4       	| $X_1-X_0.75$      	| 0.22 	| 6.99               	|   	|

Here, $X_t$ is the difference between the home team's score and the visiting team's score after $t(100)$ percent of the game is played. The data show the mean and standard deviation of those differences at the end of each quarter. Why might the data support the use of a Brownian motion model? What aspects of the data give reason to doubt the Brownian motion model?

\soln A process is Brownian motion iff there is 0 initial value, independent increments, Gaussian increments, and almost-surely continuous paths.

That the paths are almost surely continuous is trivial. It's also reasonable to assume that the initial value is 0, due to the rules of basketball. However, the fourth quarter mean differs from the other quarters, which suggests that this is not a Brownian motion process, even with drift.

## Exercise 8.16

Let $(X_t)_{t\ge 0}$ and $(Y_t)_{t \ge 0}$ be independent, standard Brownian motions. Show that $Z_t = a(X_t-Y_t)$ defines a standard Brownian motion for some $a$. Find $a$.

\soln Since the difference of a.s. continuous paths is also almost surely continuous, the process $Z_t$ is a.s. continuous. The mean function is also 0 since the linear combination of Gaussian r.v.s is Gaussian. Letting $0 < s < t$, the covariance function is:
$$
\begin{aligned}
\Cov(Z_s, Z_t) &= \Cov(a(X_s-Y_s),a(X_t-Y_t) \\
&= a^2[\Cov(X_s,X_t) - \Cov(X_s,Y_t) - \Cov(Y_s,X_t) + \Cov(Y_s,Y_t)] \\
&= a^2[\min(s,t) + \min(s,t)] \\
&= 2a^2\min(s,t)
\end{aligned}
$$

If $a = \pm1/\sqrt{2}$, then the covariance function is $\min(s,t)$.

## Exercise 8.17

For $a > 0$, show that for standard Brownian motion the first hitting time $T_a$ has the same distribution as $1/X^2$, where $X$ is a normal random variable with mean 0 and variance $1/a^2$.

\soln Let $T_a = 1/X^2$. The CDF is:
$$
P(T_a \le t) = P(1/X^2 \le t) \\
= P(X^2 \ge 1/t) \\
= P(X \ge t^{-1/2}) + P(X \le -t^{-1/2}) \\
= 2P(X \le -t^{-1/2})
$$
Differentiating with respect to $t$:
$$
\begin{aligned}
P(T_a = t) &= \frac{d}{dt} 2P(X \le -t^{-1/2}) \\
&= 2 \cdot 1/2t^{-3/2} \cdot f_X(-t^{1/2}) \\
&= \frac{1}{\sqrt{t^3}} \cdot \frac{1}{\sqrt{2\pi/a^2}}\exp\left(-\frac{(-t^{-1/2})^2}{2/a^2}\right) \\
&= \frac{|a|}{\sqrt{2\pi t^3}}\exp\left(-\frac{a^2}{2t}\right) \\
\end{aligned}
$$

This corresponds to the first hitting time distribution.

## Exercise 8.18
Show that the first hitting time $T_a$ has the same distribution as $a^2T_1$.

\soln $a^2 T_1$ is the time for a process to hit 1, scaled by $a^2$. Assuming that the CDFs are equal:
$$
P(T_a \le t) = P(a^2 T_1 \le t) = P(T_1 \le t/a^2)
$$

Differentiating with respect to $t$:
$$
\begin{aligned}
\frac{\partial}{\partial t} P(T_a \le t) &= \frac{\partial}{\partial t}P(T_1 \le t/a^2) \\
&= \frac{1}{a^2} f_{T_1}(t/a^2) \\
&= \frac{1}{a^2} \cdot \frac{1}{\sqrt{2\pi (t/a^2)^3}} \exp\left(-\frac{1^2}{2t/a^2}\right) \\
&= \frac{1}{a^2} \cdot \frac{|a^3|}{\sqrt{2\pi t^3}} \exp\left(-\frac{a^2}{2t}\right) \\
&= \frac{|a|}{\sqrt{2\pi t^3}}\exp\left(-\frac{a^2}{2t}\right)
\end{aligned}
$$

## Exercise 8.19
Find the mean and variance of the maximum value of standard Brownian motion on [0,t].

\soln Let $M_t$ be the maximum of the standard Brownian motion on [0,t], and let $a>0$. We can split the event $\{M_t>a\}$ into 2 possibilities: either $B_t$ is greater than $a$ at time $t$ or $B_t$ is less than $a$ at time $t$. If at time $t$ the Brownian motion exceeds $a$, then it's a certainty that $M_t > a$, so $\{B_t>a\}$ implies $\{M_t > a\}$, so:
$$
\{M_t > a\} = \{M_t > a, B_t > a\} \cup \{M_t>a, B_t \le a\} \\
= \{B_t > a\} \cup \{M_t>a, B_t \le a\} 
$$

In the second event, consider a time $0 < t^* \le t$ where $B_{t^*}$ hit $a$, then $B_t$ finishes at $t$ under the level $a$. By the reflection principle, the path of the Brownian motion on the interval $[t^*, t]$ that finishes below $a$ corresponds to a path that finishes at least $a$ at time $t$, which gives $\{M_t > a, B_t \le a\}$ as corresponding to the same event $\{\tilde{B_t} \ge a\} = B_t > a$.
$$
\begin{gathered}
P(M_t > a) = P(B_t > a) + P(B_t > a) = 2P(B_t>a)\\
P(M_t > a) = 2 \int_a^\infty \frac{1}{\sqrt{2\pi t}} \exp\left(-\frac{x^2}{2t}\right) dx \\
P(M_t = a) = \frac{\partial}{\partial a} [1-P(M_t > a)] = -2\frac{\partial}{\partial a} \int_a^\infty \frac{1}{\sqrt{2\pi t}} \exp\left(-\frac{x^2}{2t}\right) dx \\
= -2\left[0 - \frac{1}{\sqrt{2\pi t}} \exp\left(-\frac{x^2}{2t}\right)\right] \\
= \sqrt{\frac{2}{\pi t}} \exp\left(-\frac{x^2}{2t}\right), x > 0
\end{gathered}
$$
This is the distribution for the absolute value of the Brownian motion path, $|B_t|$.

An alternative formulation draws on the already calculated hitting time distribution $T_a$. The event $\{M_t > a\}$ corresponds to the hitting time being prior to $t$, so this event is $\{T_a < t\}$:

$$
P(M_t >a ) = P(T_a < t) \\
= \int_0^t \frac{a}{\sqrt{2\pi s^3}}\exp\left(-\frac{a^2}{2s}\right) ds
$$
Let $a^2/s \Rightarrow x^2/t$. Then $s = (a^2t)x^{-2} \Rightarrow ds = -2(a^2t)x^{-3}\,dx$, and $x^2 = a^2t/s$,
$$
\begin{aligned}
x^+ &= \sqrt{\lim_{s \rightarrow t} \frac{a^2t}{s}} = \sqrt{a^2} = a \\
x^- &= \sqrt{\lim_{s \rightarrow 0} \frac{a^2t}{s}} = \infty
\end{aligned}
$$

Substituting:
$$
\begin{gathered}
P(M_t > a) = \int_{x=\infty}^{x=a} \frac{a}{\sqrt{2\pi}} (a^2tx^{-2})^{-3/2}\exp\left(-\frac{x^2}{2t}\right) \cdot -2a^2tx^{-3}\, dx \\
= -2\int_{x=\infty}^{x=a}  \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{x^2}{2t}\right) \cdot a^{-3}t^{-3/2}x^{3}a^2tx^{-3}\, dx \\
= 2\int_{a}^{\infty} \frac{1}{\sqrt{2\pi t}}\exp\left(-\frac{x^2}{2t}\right)\, dx
\end{gathered}
$$
This is the same expression as the CDF from above.

$$
\begin{aligned}
E(M_t) &= E(|B_t|) \\
&= \int_0^\infty \sqrt{\frac{2}{\pi t}} x\exp\left(-\frac{x^2}{2t}\right)\, dx \\
&= \sqrt{\frac{2}{\pi t}}\int_0^\infty x\exp\left(-\frac{x^2}{2t}\right)\, dx 
\end{aligned}
$$
Let $u = x^2/2, du = xdx$:

$$
\begin{aligned}
E(M_t) &= \sqrt{\frac{2}{\pi t}}\int_0^\infty \exp\left(-u/t\right)\, du \\
&= -t\sqrt{\frac{2}{\pi t}} \exp(-u/t)|_{0}^\infty \\
&=\sqrt{\frac{2t}{\pi}} 
\end{aligned}
$$
To get the variance:
$$
\begin{aligned}
\Var(M_t) &= \Var(|B_t|)\\
&= E(|B_t|^2) - E(|B_t|)^2 \\
&= E(B_t^2) - E(|B_t|)^2 \\
&= [\Var(B_t) + E(B_t)^2] - E(|B_t|)^2 \\
&= t - \frac{2t}{\pi} \\
&= t\left(1 - \frac{2}{\pi}\right)
\end{aligned}
$$

## Exercise 8.20
Use the reflection principle to show
$$
P(M_t \ge a, B_t \le a-b) = P(B_t \ge a+b), \,\text{for }a,b>0.
$$

\soln Since $T_a: \inf\{t \ge 0: B_t \ge a\}$ is a hitting time, we can apply the reflection principle. 

Consider the process
$$
\tilde{B_t} = \begin{cases}
B_t & t < T_a \\
2a-B_t & t \ge T_a
\end{cases}
$$
Consider the case that this process hits level $a$ by time $t$ and is at most $a-b$ at time $t$. Then, the event $\{M_t \ge a, B_t \le a-b\}$ corresponds to the event $\{\tilde{B_t} \ge a+b\}$ (which is the same distance $b$ from line $a$, reflected the other direction).

## Exercise 8.21
From standard Brownian motion, let $X_t$ be the process defined by
$$
X_t = \begin{cases}
B_t, &\text{if }t < T_a, \\
a, &\text{if }t \ge T_a
\end{cases}
$$
where $T_a$ is the first hitting time of $a>0$. The process $(X_t)_{t\ge 0}$ is called _Brownian motion absorbed at a_. The distribution of $X_t$ has discrete and continuous parts.

(a) Show
$$
P(X_t = a) = \frac{2}{\sqrt{2 \pi t}}\int_a^\infty e^{-x^2/2t}\, dx
$$

\soln 
$$
\begin{gathered}
P(X_t = a)\\
= P(X_t = a | T_a > t) P(T_a > t) + P(X_t = a | T_a \le t) P(T_a \le t) \\
= 0\cdot P(T_a > t) + 1 \cdot P(T_a \le t) \\
= P(T_a \le t) \\
= \frac{2}{\sqrt{2 \pi t}}\int_a^\infty e^{-x^2/2t}\, dx
\end{gathered}
$$

(b) For $x < a$, show
$$
P(X_t \le x) = P(B_t \le x) - P(B_t \le x-2a) = \frac{1}{\sqrt{2\pi t}}\int_{x-2a}^x e^{-z^2/2t}\, dz
$$

\soln In order for the process to be at most $x$ at time $t$, the process can't have hit $a$, so $M_t < a$. We are therefore looking for the joint probability that the process is under $a$ at all times and is at most $x$ at time $t$.

$$
P(X_t \le x) = P(B_t \le x, M_t < a)
$$
Examine the event $\{B_t \le x\}$ for a standard Brownian motion. If $B_t < x$, then the process could have either hit $a$ or stayed under $a$ until time $t$. These two cases are disjoint:
$$
\begin{gathered}
P(B_t \le x) = P(B_t \le x, M_t < a) + P(B_t \le x, M_t \ge a) \\
P(B_t \le x, M_t < a) = P(B_t \le x) - P(B_t \le x, M_t \ge a)
\end{gathered}
$$
Plugging into the previous equality:
$$
\begin{aligned}
P(X_t \le x) &= P(B_t \le x, M_t < a) \\
&= P(B_t \le x) - P(B_t \le x, M_t \ge a) \\
&= P(B_t \le x) - P(B_t \ge a + (a-x)) \\
&= P(B_t \le x) - P(B_t \ge 2a - x) \\
&= P(B_t \le x) - P(B_t \le x-2a)
\end{aligned}
$$

The last equality is due to the reflection of $B_t$ over the $x$-axis. This probability is:
$$
P(B_t \le x) - P(B_t \le x -2a) = \int_{x-2a}^x \frac{1}{\sqrt{2\pi t}}\exp(-x^2/2t) \, dx
$$

## Exercise 8.22
Let $Z$ be the smallest zero of the standard Brownian motion past $t$. Show that
$$
P(Z\le z) = \frac{2}{\pi} \arccos\sqrt{\frac{t}{z}}, \, \text{for }z > 0
$$

\soln Let $z_{t,z} = \frac{2}{\pi} \arccos \sqrt{\frac{t}{z}}$ be the probability that there is at least 1 zero in the interval $(t,z)$. If there are no zeros in the interval $(t,z)$, then $Z > z$.

$$
P(Z \le z) = 1- P(Z \ge z) = 1 - (1 - z_{t,z}) = \frac{2}{\pi} \arccos\sqrt{\frac{t}{z}}
$$

## Exercise 8.23 NOT DONE
Let $0 < r < s < t$.

(a) Assume that standard Brownian motion is not zero in $(r,s)$. Find the probability that standard Brownian motion is not zero in $(r,t)$.

\soln Let $\tilde{Z}_{a,b}$ be the event that the Brownian motion is not 0 at any time in the interval $(a,b)$. Then this probability is:
$$
P(\tilde Z_{r,t} | \tilde Z_{r,s}) = \frac{P(\tilde Z_{r,t} \cap \tilde Z_{r,s})}{P(\tilde Z_{r,s})}
$$

## Exercise 8.24
Derive the mean and variance of geometric Brownian motion.

\soln Let $G_t = G_0e^{\mu t + \sigma B_t}$. Using the MGF of the Normal distribution, we have
$$
M_{B_t}(\sigma) = E(e^{\sigma B_t}) = e^{\mu t + t\sigma^2/2} = e^{\sigma^2t/2}
$$
Thus the expectation is:
$$
E(G_t) = E\left(G_0e^{\mu t + \sigma B_t}\right) = G_0 e^{\mu t} E\left(e^{\sigma B_t}\right) \\
= G_0 e^{\mu t+\sigma^2t/2}
$$

Variance:
$$
\Var(G_t) = E(G_t^2) - E(G_t)^2 \\
E(G_t^2) = E\left[G_0^2e^{2(\mu t + \sigma B_t)}\right] \\
= G_0^2e^{2\mu t}E\left[e^{2\sigma B_t}\right] \\
= G_0^2e^{2\mu t} M_{B_t}(2\sigma)\\
= G_0^2e^{2\mu t} e^{2\sigma^2t} \\
\Var(G_t) = G_0^2 \left[e^{2 \mu t}e^{2\sigma^2 t} - e^{2\mu t}e^{ \sigma^2 t}\right] \\
= G_0^2e^{2\mu t+\sigma^2t}\left[e^{\sigma^2 t} - 1\right]
$$

## Exercise 8.25
The price of a stock is modeled with a geometric Brownian motion with drift $\mu = -0.25$ and volatility $\sigma = 0.4$. The stock currently sells for \$35. What is the probability that the price will be at least \$40 in 1 year?

\soln
$$
\begin{gathered}
P(G_1 > 40) = P(35e^{-0.25(1) + 0.4B_1} > 40) \\
= P(e^{-0.25 + 0.4B_1} > 40/35) \\
= P(-0.25 + 0.4B_1 > \log (40/35)) \\
= P\left(B_1 > \frac{0.25 + \log(40/35)}{0.4}\right) \approx 0.169
\end{gathered}
$$

```{r eval=FALSE, include=FALSE}
# returns one sample path of geometric brownian motion
geom_bm <- function(t, mu, sigma, g_0) {
  steps <- 1000
  bm <- c(0, cumsum(rnorm(steps, 0, sqrt(t/steps))))
  xs <- seq(0, t, length = steps+1)
  
  g_0 * exp(mu * xs + sigma * bm)
}

exercise_8_25 <- function(nsims, t, mu, sigma, g_0) {
  res <- numeric(nsims)
  
  # simulate
  for (i in 1:nsims) {
    res[i] <- last(geom_bm(t, mu, sigma, g_0))
  }
  res
}

(exercise_8_25(nsims=1e4, t=1, mu=-0.25, sigma=0.4, g_0=35) > 40) %>% mean
```

## Exercise 8.26
For the stock price model in Exercise 8.25, assume that an option is available to purchase the stock in six months for \$40. Find the expected payoff of the option.

\soln Let the price of the stock in half a year be $G_{0.5}$. Then, the expected payoff of the option is:

$$
\begin{gathered}
E(\max\{G_{0.5}-40,0\}) = G_0 e^{t(\mu + \sigma^2/2)} P\left(Z > \frac{\beta - \mu t}{\sqrt{t}}\right) \\ - K P\left(Z > \frac{\beta}{\sqrt{t}}\right)
\end{gathered}
$$

Calculating $\beta$:
$$
\beta = (\ln (K/G_0) - \mu t ) / \sigma = (\ln(40/35) - (-0.25)(0.5))/0.4 = (\log (8/7) + 0.125)/0.4) = 2.5\log(8/7) + 0.3125
$$

Then the expected payoff is:
$$
35 \exp\left(0.5(-0.25+0.4^2/2\right) P\left(Z > \frac{\beta - 0.4(0.5)}{\sqrt{0.5}}\right) - 40P\left(Z > \frac{\beta }{\sqrt{0.5}}\right) \\
\approx 1.272
$$

```{r 8.25, eval=FALSE, include=FALSE}
# price_of_option
exercise_8_26_theoretical <- function(t, mu, sigma, g_0, K) {
  beta <- 1/sigma * (log(K/g_0) - mu *t)
  price_of_option <- g_0 * exp(t * (mu + sigma^2/2)) * (1-pnorm((beta - sigma * t) / sqrt(t))) - K * (1-pnorm(beta / sqrt(t)))
  
  price_of_option
}

# simulate
exercise_8_26_sim <- function(nsims, t, mu, sigma, g_0, K) {
  # first simulate 1000 stock prices
  g_t <- numeric(nsims)
  for (i in 1:nsims) {
    g_t[i] <- last(geom_bm(t, mu, sigma, g_0))
  }
  
  # expected payoff: E(max(g_t - k, 0))
  pmax(g_t - K, 0) %>% mean
}

exercise_8_26_theoretical(t=0.5, mu=-0.25, sigma=0.4, g_0=35, K=40)
exercise_8_26_sim(nsims=1000, t=0.5, mu=-0.25, sigma=0.4, g_0=35, K=40)
```

## Exercise 8.27
Assume that $Z_0, Z_1, \dots$ is a branching process whose offspring distribution has mean $\mu$. Show that $Z_n/\mu^n$ is a martingale.

\soln To show that $Z_n/\mu^n$ is a martingale, we must show that the martingale property holds and the absolute expectation is bounded for all $n$. Let $0 \le m < n$ be a time before time $n$.

Using LOTE and referencing Dobrow 4.2:
$$
E(\frac{Z_n}{\mu^n}\mid \frac{Z_{m}}{\mu^{m}} \text{ for all } 1 \le m < n) = E(\frac{1}{\mu^n}\sum_{i=1}^{\frac{Z_{n-1}}{{\mu^{n-1}}} \cdot \mu^{n-1}}X_i \mid \frac{Z_{n-1}}{\mu^{n-1}}) \\
= \frac{1}{\mu^n} \sum_{i=1}^{\frac{Z_{n-1}}{{\mu^{n-1}}} \cdot \mu^{n-1}} E(X_i \mid \frac{Z_{n-1}}{\mu^{n-1}}) \\
= \frac{1}{\mu^n} \sum_{i=1}^{\frac{Z_{n-1}}{{\mu^{n-1}}} \cdot \mu^{n-1}} E(X_i ) \\
= \frac{1}{\mu^n} \cdot \left(\frac{Z_{n-1}}{{\mu^{n-1}}} \cdot \mu^{n-1} \right) \cdot\mu \\
= \frac{Z_{n-1}}{\mu^{n-1}}
$$
