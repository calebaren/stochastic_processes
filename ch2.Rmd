---
title: "Chapter 2"
author: "calebren"
date: "2025-10-02"
output: pdf_document
---
\newcommand{\Var}{\textrm{Var}}
\newcommand{\Cov}{\textrm{Cov}}
\newcommand{\soln}{\textbf{Solution:}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE, include = FALSE)
```

# Exercises
## Exercise 2.1
A Markov chain has transition matrix
$$
P = \bordermatrix{
  & 1 & 2 & 3 \cr
1 & 0.1 & 0.3 & 0.6 \cr
2 & 0   & 0.4 & 0.6 \cr
3 & 0.3 & 0.2 & 0.5 
}
$$
with initial distribution $\alpha = (0.2, 0.3, 0.5)$. Find the following:
(a) $P(X_7 = 3 | X_6 = 2)$

\soln By time homogeneity,
$$
P(X_7 = 3 | X_6 = 2) = P(X_1 = 3 | X_0 = 2) = P_{23} = 0.6
$$

(b) $P(X_9=2|X_1=2,X_5=1,X_7=3)$

\soln By the Markov property and time homogeneity, 
$$
\begin{gathered}
P(X_9=2|X_1=2,X_5=1,X_7=3) = P(X_9 =2| X_7 = 3) \\
= P(X_2=2|X_0=3) (P^2)_{23} \\
= 0.54
\end{gathered}
$$

(c) $P(X_0=3|X_1=1)$

\soln By Bayes' rule,
$$
\begin{gathered}
P(X_0 = 3|X_1=1) = \frac{P(X_1=1|X_0=3)P(X_0=3)}{P(X_1=1)} \cr
= \frac{P_{31}\alpha_3}{(\alpha P)_1} \cr
= \frac{0.3\cdot 0.5}{0.17} \cr
= \frac{15}{17} \approx 0.88
\end{gathered}
$$

```{r exercise 2.1c}
exercise_2_1c <- function() {
  # sample a bunch from alpha
  nsim <- 1000
  initial <- sample(1:3, size = nsim, replace = T, prob = alpha)
  
  # then, get the next state based on x
  nxt <- sapply(initial, FUN = function(i) sample(1:3, size = 1, prob = pmat[i,]))
  
  # calculate prob that initial = 3, based on next = 1.
  mean(initial[nxt == 1] == 3)
}
```

(d) $E(X_2)$

\soln 
$$
E(X_2) = \sum_k k P(X_2 = k) = \sum_k k (\alpha P^2)_k = 2.363
$$

```{r exercise 2.1d}
# start with initial distribution
exercise_2_1d <- function() {
  nsim <- 1e4
  states <- sample(1:3, size = nsim, replace = T, prob = alpha)
  states <- sapply(states, FUN = function(i) sample(1:3, size = 1, prob = pmat[i,]))
  states <- sapply(states, FUN = function(i) sample(1:3, size = 1, prob = pmat[i,]))
  mean(states)
}
```

## Exercise 2.2

Let $X_0, X_1, \dots$ be a Markov chain with transition matrix
$$
\bordermatrix{
& 1 & 2 & 3 \cr
1 & 0 & 1/2 & 1/2 \cr
2 & 1 & 0 & 0 \cr
3 & 1/3 & 1/3 & 1/3
}
$$
and initial distribution $\alpha = (1/2, 0, 1/2)$. Find the following:
(a) $P(X_2=1|X_1=3)$
\soln $P(X_2=1|X_1=3) = P_{31} = 1/3$

(b) $P(X_1=3, X_2=1)$
\soln $P(X_1=3,X_2=2) = (\alpha P)_3 P_{31}$

```{r}
initial <- sample(1:3, size = 1e4, replace = T, prob = alpha)
first <- sapply(initial, function(i) sample(1:3, size = 1, prob = pmat[i,]))
second <- sapply(first, function(i) sample(1:3, size = 1, prob = pmat[i,]))
mean(first == 3 & second == 1)
```

## Exercise 2.3 NOT STARTED

## Exercise 2.4
For the general two-state chain with transition matrix
$$
P = 
\bordermatrix{
& a & b \cr
a & 1-p & p \cr
b & q & 1-q
}
$$
and initial distribution $\alpha = (\alpha_1, \alpha_2)$, find the following:
(a) the two-step transition matrix
\soln

$$
\begin{aligned}
P^2 &= \begin{bmatrix}
1-p & p \\
q & 1-q
\end{bmatrix} \begin{bmatrix}
1-p & p \\
q & 1-q
\end{bmatrix} \\
&= \begin{bmatrix}
(1-p)^2 + pq & (1-p)p + p(1-q) \\
q(1-p) + q(1-q) & pq + (1-q)^2
\end{bmatrix} \\
&= \begin{bmatrix}
(1-p)^2 + pq & p(2-p-q) \\
q(2-p-q) & (1-q)^2 + pq
\end{bmatrix}
\end{aligned}
$$

(b) the distribution of $X_1$
\soln
$$
\begin{aligned}
X_1 &= \alpha P \\
&= \begin{bmatrix}\alpha_1 & \alpha_2\end{bmatrix} \begin{bmatrix}
1-p & p \\
q & 1-q
\end{bmatrix} \\
&= \begin{bmatrix}
\alpha_1-\alpha_1p + \alpha_2q & \alpha_1p + \alpha_2-\alpha_2 q
\end{bmatrix}
\end{aligned}
$$

## Exercise 2.5
Consider a random walk on $\{0,\dots,k\}$, which moves left and right with respective probabilities $q$ and $p$. If the walk is at 0 it transitions to 1 on the next step. If the walk is at $k$ it transitions to $k-1$ on the next step. This is called \textrm{random walk with reflecting boundaries}. Assume that $k=3, q=1/4, p=3/4$, and the initial distribution is uniform. For the following, use technology if needed.

(a) Exhibit the transition matrix.

\soln The transition matrix is:
$$
P = \bordermatrix{
  & 0 & 1 & 2 & 3 \cr
0 & 0 & 1 & 0 & 0 \cr
1 & q & 0 & p & 0 \cr
2 & 0 & q & 0 & p \cr
3 & 0 & 0 & 1 & 0
} \\
= \bordermatrix{
  & 0 & 1 & 2 & 3 \cr
0 & 0 & 1 & 0 & 0 \cr
1 & 1/4 & 0 & 3/4 & 0 \cr
2 & 0 & 1/4 & 0 & 3/4 \cr
3 & 0 & 0 & 1 & 0
}
$$

(b) Find $P(X_7=1|X_0=3,X_2=2,X_4=2)$.

\soln By the Markov property, this probability depends on the most recent state, so $P = P(X_7 = 1 | X_4 = 2) = (P^3)_{21} = 19/64$.

$$
\begin{aligned}
P^3 &= \begin{bmatrix}
 0 & 1 & 0 & 0 \cr
 1/4 & 0 & 3/4 & 0 \cr
0 & 1/4 & 0 & 3/4 \cr
0 & 0 & 1 & 0
\end{bmatrix} \begin{bmatrix}
 0 & 1 & 0 & 0 \cr
 1/4 & 0 & 3/4 & 0 \cr
0 & 1/4 & 0 & 3/4 \cr
0 & 0 & 1 & 0
\end{bmatrix} \begin{bmatrix}
 0 & 1 & 0 & 0 \cr
 1/4 & 0 & 3/4 & 0 \cr
0 & 1/4 & 0 & 3/4 \cr
0 & 0 & 1 & 0
\end{bmatrix} \\
&= \begin{bmatrix}
 1/4 & 0 & 3/4 & 0 \cr
0 & 7/16 & 0 & 9/16 \cr
1/16 & 0 & 15/16 & 0 \cr
0 & 1/4 & 0 & 3/4 
\end{bmatrix} \begin{bmatrix}
 0 & 1 & 0 & 0 \cr
 1/4 & 0 & 3/4 & 0 \cr
0 & 1/4 & 0 & 3/4 \cr
0 & 0 & 1 & 0
\end{bmatrix} \\
&= \begin{bmatrix}
0 & 7/16 & 0 & 9/16 \cr
7/64 & 0 & 57/64 & 0 \cr
0 & 19/64 & 0 & 45/64 \cr
1/16 & 0 & 15/16 & 0
\end{bmatrix}
\end{aligned}
$$

(c) Find $P(X_3=1, X_5=3)$.

\soln $P(X_3=1,X_5=3) = (\alpha P^3)_1 (P^2)_{13} = 0.103$

```{r}
exercise_2_5 <- function() {
  steps <- 5
  nsim <- 1e5
  
  data <- matrix(nrow = nsim, ncol = steps+1)
  pmat <- matrix(c(0, 1, 0, 0, 1/4, 0, 3/4, 0, 0, 1/4, 0, 3/4, 0, 0, 1, 0), nrow = 4, byrow = T)
  
  # initial state
  data[,1] <- sample(1:4, size = nsim, replace = T)
  for (j in 2:(steps+1)) {
    for (k in 1:nsim) {
      data[k, j] <- sample(1:4, size = 1, prob = pmat[data[k,(j-1)],])
    }
  }
  data[,4]==2 & data[,6]==4
}
```

## Exercise 2.6

A tetrahedron die has four faces labeled 1,2,3, and 4. In repeated independent rolls of the die $R_0, R_1, \dots,$ let $X_n = \max\{R_0,\dots,R_n\}$ be the maximum value after $n+1$ rolls, for $\ge 0$.
(a) Give an intuitive argument for why $X_0, X_1,\dots,$ is a Markov chain, and exhibit the transition matrix.

\soln Each subsequent roll is independent from the previous rolls. In order to determine what $X_n$ is, we only need the state of $X_{n-1}$ and the current roll, which is independent of any prior states or future states. The transition matrix is:
$$
P = \bordermatrix{
  & 1 & 2 & 3 & 4 \cr
1 & 1/4 & 1/4 & 1/4 & 1/4 \cr
2 & 0  & 1/2 & 1/4 & 1/4 \cr
3 & 0 & 0 & 3/4 & 1/4 \cr
4 & 0 & 0 & 0 & 1
}
$$

(b) Find $P(X_3 \ge 3).

\soln
$$
P(X_3 \ge 3) = P(X_3 = 3) + P(X_3=4) = 0.9375
$$

```{r}
exercise_2_6 <- function() {
  pmat <- matrix(c(0.25, 0.25, 0.25, 0.25,
                   0, 0.5, 0.25, 0.25,
                   0, 0, 0.75, 0.25,
                   0, 0, 0, 1),
                 byrow = T, nrow = 4)
  rep(0.25, 4) %*% (pmat %^% 3)
}

exercise_2_6()
```

## Exercise 2.7
Let $X_0, X_1, \dots$ be a Markov chain with transition matrix $P$. Let $Y_n = X_{3n}$, for $n=0, 1, 2, \dots$. Show that $Y_0, Y_1,\dots$ is a Markov chain and exhibit its transition matrix.

\soln